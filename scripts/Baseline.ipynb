{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenMIC-2018 baseline model tutorial\n",
    "\n",
    "This notebook demonstrates how to replicate the baseline modeling experiment in [(Humphrey, Durand, and McFee, 2018)](http://ismir2018.ircam.fr/doc/pdfs/203_Paper.pdf).\n",
    "\n",
    "We'll load in the pre-computed VGGish features and labels, and fit a RandomForest model for each of the 20 instrument classes using the pre-defined train-test splits provided in the repository.\n",
    "\n",
    "We'll then evaluate the models we fit, and show how to apply them to a new audio file that wasn't included in OpenMIC-2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These dependencies are necessary for loading the data\n",
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# We'll use the openmic package to preprocess new recordings\n",
    "# for classification beyond the dataset\n",
    "import openmic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "The openmic data is provided in a python-friendly format as `openmic-2018.npz`.\n",
    "\n",
    "You can load it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENMIC = np.load('openmic-2018.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X', 'Y_true', 'Y_mask', 'sample_key']\n"
     ]
    }
   ],
   "source": [
    "# What's included?\n",
    "print(list(OPENMIC.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's included in the data?\n",
    "\n",
    "- `X`: 20000 * 10 * 128 array of VGGish features\n",
    "    - First index (0..19999) corresponds to the sample key\n",
    "    - Second index (0..9) corresponds to the time within the clip\n",
    "    - Third index (0..127) corresponds to the VGGish features at each point in the 10sec clip\n",
    "    - Example `X[40, 8]` is the 128-dimensional feature vector for the 9th second in the 41st example\n",
    "- `Y_true`: 20000 * 20 array of *true* label probabilities\n",
    "    - First index corresponds to sample key, as above\n",
    "    - Second index corresponds to the label class (accordion, ..., voice)\n",
    "    - Example: `Y[40, 4]` indicates the confidence that example #41 contains the 5th instrument\n",
    "- `Y_mask`: 20000 * 20 binary mask values\n",
    "    - First index corresponds to sample key\n",
    "    - Second index corresponds to the label class\n",
    "    - Example: `Y[40, 4]` indicates whether or not we have observations for the 5th instrument for example #41\n",
    "- `sample_key`: 20000 array of sample key strings\n",
    "    - Example: `sample_key[40]` is the sample key for example #41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 10, 128)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OPENMIC['X'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([192,  30, 176, 126, 208,  85,  84,  95,  69, 234,  99, 118, 166,\n",
       "       150, 106,  68, 165, 156, 146, 206,  75, 210, 131,  49,  61, 218,\n",
       "        92, 152, 121, 167,  62, 166, 167, 237,  22, 168, 165, 137, 178,\n",
       "       132, 196,  96,  54, 166, 169, 132,  59,  27,  46, 123,  89,  47,\n",
       "        58, 116,  48, 188, 157,  28,  44, 252, 248, 100,  28, 154, 147,\n",
       "       148, 204, 104,  95,  67, 109, 147, 204, 146, 196, 222,  90, 255,\n",
       "        94, 171,  53, 133, 202, 152,  35,  55, 231, 255,  62, 227, 168,\n",
       "       192,  87, 144, 130, 255,   0,   0, 163,  75, 255, 135, 216,  68,\n",
       "         0, 199,   0, 193, 254, 114,  12, 255,   0,  74, 165,   0, 201,\n",
       "       246,   0, 127, 211, 218, 164,  57, 238, 176, 158, 255])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features for the 9th second of t\n",
    "OPENMIC['X'][80, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5    , 0.5    , 0.5    , 0.5    , 0.5    , 0.15055, 0.5    ,\n",
       "       0.5    , 0.5    , 0.5    , 0.5    , 0.5    , 0.5    , 0.5    ,\n",
       "       0.5    , 0.5    , 0.5    , 0.5    , 0.5    , 0.5    ])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OPENMIC['Y_true'][40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OPENMIC['Y_mask'][40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OPENMIC['sample_key'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'000385_249600'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OPENMIC['sample_key'][40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It will be easier to use if we make direct variable names for everything\n",
    "X, Y_true, Y_mask, sample_key = OPENMIC['X'], OPENMIC['Y_true'], OPENMIC['Y_mask'], OPENMIC['sample_key']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the class map\n",
    "\n",
    "For convenience, we provide a simple JSON object that maps class indices to names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('class-map.json', 'r') as f:\n",
    "    class_map = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accordion': 0,\n",
       " 'banjo': 1,\n",
       " 'bass': 2,\n",
       " 'cello': 3,\n",
       " 'clarinet': 4,\n",
       " 'cymbals': 5,\n",
       " 'drums': 6,\n",
       " 'flute': 7,\n",
       " 'guitar': 8,\n",
       " 'mallet_percussion': 9,\n",
       " 'mandolin': 10,\n",
       " 'organ': 11,\n",
       " 'piano': 12,\n",
       " 'saxophone': 13,\n",
       " 'synthesizer': 14,\n",
       " 'trombone': 15,\n",
       " 'trumpet': 16,\n",
       " 'ukulele': 17,\n",
       " 'violin': 18,\n",
       " 'voice': 19}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the train-test splits\n",
    "\n",
    "OpenMIC-2018 comes with a pre-defined train-test split.  Great care was taken to ensure that this split is approximately balanced and artists are not represented in both sides of the split, so please use it!\n",
    "\n",
    "This is done by sample key, not row number, so you will need to go through the `sample_key` array to slice the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's split the data into the training and test set\n",
    "# We use squeeze=True here to return a single array for each, rather than a full DataFrame\n",
    "split_train = pd.read_csv('split01_train.csv', header=None, squeeze=True)\n",
    "split_test = pd.read_csv('split01_test.csv', header=None, squeeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      000046_3840\n",
       "1    000135_483840\n",
       "2    000139_119040\n",
       "3    000141_153600\n",
       "4     000144_30720\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These two tables contain the sample keys for training and testing examples\n",
    "# Let's see the keys for the first five training example\n",
    "split_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train: 14915,  # Test: 5085\n"
     ]
    }
   ],
   "source": [
    "# How many train and test examples do we have?  About 75%/25%\n",
    "print('# Train: {},  # Test: {}'.format(len(split_train), len(split_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making sets\n",
    "These sample key maps are easier to use as sets, so let's make them sets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = set(split_train)\n",
    "test_set = set(split_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data\n",
    "\n",
    "Now that we have the sample keys for the training and testing examples, we need to partition the data arrays (`X`, `Y_true`, `Y_mask`).\n",
    "\n",
    "This is a little delicate to get right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These loops go through all sample keys, and save their row numbers\n",
    "# to either idx_train or idx_test\n",
    "#\n",
    "# This will be useful in the next step for slicing the array data\n",
    "idx_train, idx_test = [], []\n",
    "\n",
    "for idx, n in enumerate(sample_key):\n",
    "    if n in train_set:\n",
    "        idx_train.append(idx)\n",
    "    elif n in test_set:\n",
    "        idx_test.append(idx)\n",
    "    else:\n",
    "        # This should never happen, but better safe than sorry.\n",
    "        raise RuntimeError('Unknown sample key={}! Abort!'.format(sample_key[n]))\n",
    "        \n",
    "# Finally, cast the idx_* arrays to numpy structures\n",
    "idx_train = np.asarray(idx_train)\n",
    "idx_test = np.asarray(idx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = X[idx_train]\n",
    "X_test = X[idx_test]\n",
    "\n",
    "Y_mask_train = Y_mask[idx_train]\n",
    "Y_mask_test = Y_mask[idx_test]\n",
    "\n",
    "Y_true_train = Y_true[idx_train]\n",
    "Y_true_test = Y_true[idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14915, 10, 128)\n",
      "(5085, 10, 128)\n"
     ]
    }
   ],
   "source": [
    "# Print out the sliced shapes as a sanity check\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "accordion\n",
      "\tTRAIN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.96      0.98      0.97      1159\n",
      "       True       0.95      0.87      0.91       374\n",
      "\n",
      "avg / total       0.96      0.96      0.96      1533\n",
      "\n",
      "\tTEST\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.84      0.94      0.89       423\n",
      "       True       0.60      0.35      0.44       115\n",
      "\n",
      "avg / total       0.79      0.81      0.79       538\n",
      "\n",
      "----------------------------------------------------\n",
      "banjo\n",
      "\tTRAIN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.95      0.96      0.96      1148\n",
      "       True       0.92      0.90      0.91       592\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1740\n",
      "\n",
      "\tTEST\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.80      0.85      0.83       338\n",
      "       True       0.58      0.50      0.54       140\n",
      "\n",
      "avg / total       0.74      0.75      0.74       478\n",
      "\n",
      "----------------------------------------------------\n",
      "bass\n",
      "\tTRAIN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.95      0.98      0.96      1010\n",
      "       True       0.94      0.86      0.90       415\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1425\n",
      "\n",
      "\tTEST\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.81      0.91      0.86       329\n",
      "       True       0.69      0.49      0.57       134\n",
      "\n",
      "avg / total       0.78      0.79      0.78       463\n",
      "\n",
      "----------------------------------------------------\n",
      "cello\n",
      "\tTRAIN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.96      0.92      0.94       866\n",
      "       True       0.89      0.94      0.92       598\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1464\n",
      "\n",
      "\tTEST\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.77      0.78      0.78       259\n",
      "       True       0.75      0.73      0.74       226\n",
      "\n",
      "avg / total       0.76      0.76      0.76       485\n",
      "\n",
      "----------------------------------------------------\n",
      "clarinet\n",
      "\tTRAIN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.90      0.99      0.94      1349\n",
      "       True       0.96      0.63      0.76       396\n",
      "\n",
      "avg / total       0.91      0.91      0.90      1745\n",
      "\n",
      "\tTEST\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.80      0.95      0.87       503\n",
      "       True       0.44      0.13      0.20       137\n",
      "\n",
      "avg / total       0.72      0.78      0.73       640\n",
      "\n",
      "----------------------------------------------------\n",
      "cymbals\n",
      "\tTRAIN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.99      0.90      0.94       485\n",
      "       True       0.94      1.00      0.97       814\n",
      "\n",
      "avg / total       0.96      0.96      0.96      1299\n",
      "\n",
      "\tTEST\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.92      0.85      0.88       139\n",
      "       True       0.93      0.97      0.95       297\n",
      "\n",
      "avg / total       0.93      0.93      0.93       436\n",
      "\n",
      "----------------------------------------------------\n",
      "drums\n",
      "\tTRAIN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       1.00      0.95      0.97       495\n",
      "       True       0.97      1.00      0.98       828\n",
      "\n",
      "avg / total       0.98      0.98      0.98      1323\n",
      "\n",
      "\tTEST\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.93      0.79      0.85       146\n",
      "       True       0.90      0.97      0.93       278\n",
      "\n",
      "avg / total       0.91      0.91      0.90       424\n",
      "\n",
      "----------------------------------------------------\n",
      "flute\n",
      "\tTRAIN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.92      0.98      0.95      1050\n",
      "       True       0.94      0.82      0.88       472\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1522\n",
      "\n",
      "\tTEST\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.88      0.82       387\n",
      "       True       0.60      0.39      0.47       175\n",
      "\n",
      "avg / total       0.71      0.73      0.71       562\n",
      "\n",
      "----------------------------------------------------\n",
      "guitar\n",
      "\tTRAIN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.99      0.98      0.98       362\n",
      "       True       0.99      1.00      0.99       852\n",
      "\n",
      "avg / total       0.99      0.99      0.99      1214\n",
      "\n",
      "\tTEST\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.93      0.95      0.94       150\n",
      "       True       0.98      0.96      0.97       286\n",
      "\n",
      "avg / total       0.96      0.96      0.96       436\n",
      "\n",
      "----------------------------------------------------\n",
      "mallet_percussion\n",
      "\tTRAIN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.97      0.94      0.95       802\n",
      "       True       0.91      0.96      0.93       522\n",
      "\n",
      "avg / total       0.95      0.95      0.95      1324\n",
      "\n",
      "\tTEST\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.74      0.79      0.76       267\n",
      "       True       0.71      0.65      0.68       211\n",
      "\n",
      "avg / total       0.72      0.73      0.72       478\n",
      "\n",
      "----------------------------------------------------\n",
      "mandolin\n",
      "\tTRAIN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.94      0.95      0.94      1185\n",
      "       True       0.91      0.88      0.90       652\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1837\n",
      "\n",
      "\tTEST\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.81      0.83      0.82       434\n",
      "       True       0.59      0.56      0.58       193\n",
      "\n",
      "avg / total       0.74      0.75      0.74       627\n",
      "\n",
      "----------------------------------------------------\n",
      "organ\n",
      "\tTRAIN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.95      0.99      0.97       977\n",
      "       True       0.98      0.90      0.94       482\n",
      "\n",
      "avg / total       0.96      0.96      0.96      1459\n",
      "\n",
      "\tTEST\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.77      0.93      0.84       310\n",
      "       True       0.62      0.31      0.41       121\n",
      "\n",
      "avg / total       0.73      0.75      0.72       431\n",
      "\n",
      "----------------------------------------------------\n",
      "piano\n",
      "\tTRAIN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       1.00      0.97      0.98       420\n",
      "       True       0.99      1.00      0.99       885\n",
      "\n",
      "avg / total       0.99      0.99      0.99      1305\n",
      "\n",
      "\tTEST\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.93      0.87      0.90       130\n",
      "       True       0.94      0.97      0.96       285\n",
      "\n",
      "avg / total       0.94      0.94      0.94       415\n",
      "\n",
      "----------------------------------------------------\n",
      "saxophone\n",
      "\tTRAIN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.96      0.90      0.93       906\n",
      "       True       0.90      0.96      0.93       830\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1736\n",
      "\n",
      "\tTEST\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.81      0.77      0.79       324\n",
      "       True       0.77      0.81      0.79       305\n",
      "\n",
      "avg / total       0.79      0.79      0.79       629\n",
      "\n",
      "----------------------------------------------------\n",
      "synthesizer\n",
      "\tTRAIN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.99      0.96      0.97       399\n",
      "       True       0.98      1.00      0.99       823\n",
      "\n",
      "avg / total       0.98      0.98      0.98      1222\n",
      "\n",
      "\tTEST\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.92      0.88      0.90       112\n",
      "       True       0.95      0.97      0.96       268\n",
      "\n",
      "avg / total       0.94      0.94      0.94       380\n",
      "\n",
      "----------------------------------------------------\n",
      "trombone\n",
      "\tTRAIN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.93      0.97      0.95      1405\n",
      "       True       0.94      0.84      0.89       635\n",
      "\n",
      "avg / total       0.93      0.93      0.93      2040\n",
      "\n",
      "\tTEST\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.82      0.87      0.84       492\n",
      "       True       0.67      0.58      0.62       228\n",
      "\n",
      "avg / total       0.77      0.78      0.77       720\n",
      "\n",
      "----------------------------------------------------\n",
      "trumpet\n",
      "\tTRAIN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.94      0.95      0.95      1303\n",
      "       True       0.91      0.91      0.91       828\n",
      "\n",
      "avg / total       0.93      0.93      0.93      2131\n",
      "\n",
      "\tTEST\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.84      0.80       467\n",
      "       True       0.72      0.61      0.66       318\n",
      "\n",
      "avg / total       0.74      0.75      0.74       785\n",
      "\n",
      "----------------------------------------------------\n",
      "ukulele\n",
      "\tTRAIN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.94      0.97      0.95      1279\n",
      "       True       0.92      0.86      0.89       556\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1835\n",
      "\n",
      "\tTEST\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.81      0.88      0.84       408\n",
      "       True       0.66      0.52      0.58       182\n",
      "\n",
      "avg / total       0.76      0.77      0.76       590\n",
      "\n",
      "----------------------------------------------------\n",
      "violin\n",
      "\tTRAIN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.99      0.86      0.92       623\n",
      "       True       0.90      1.00      0.94       779\n",
      "\n",
      "avg / total       0.94      0.93      0.93      1402\n",
      "\n",
      "\tTEST\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.81      0.69      0.75       237\n",
      "       True       0.83      0.90      0.86       394\n",
      "\n",
      "avg / total       0.82      0.82      0.82       631\n",
      "\n",
      "----------------------------------------------------\n",
      "voice\n",
      "\tTRAIN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.99      0.91      0.95       426\n",
      "       True       0.95      1.00      0.97       764\n",
      "\n",
      "avg / total       0.97      0.97      0.97      1190\n",
      "\n",
      "\tTEST\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.92      0.90      0.91       150\n",
      "       True       0.93      0.95      0.94       224\n",
      "\n",
      "avg / total       0.93      0.93      0.93       374\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This dictionary will include the classifiers for each model\n",
    "models = dict()\n",
    "\n",
    "# We'll iterate over all istrument classes, and fit a model for each one\n",
    "# After training, we'll print a classification report for each instrument\n",
    "for instrument in class_map:\n",
    "    \n",
    "    # Map the instrument name to its column number\n",
    "    inst_num = class_map[instrument]\n",
    "    \n",
    "    # Initialize a new classifier\n",
    "    clf = RandomForestClassifier(max_depth=8, random_state=0)\n",
    "    \n",
    "    # First, we need to select down to the data for which we have annotations\n",
    "    # This is what the mask arrays are for\n",
    "    train_inst = Y_mask_train[:, inst_num]\n",
    "    test_inst = Y_mask_test[:, inst_num]\n",
    "    \n",
    "    # Here, we're using the Y_mask_train array to slice out only the training examples\n",
    "    # for which we have annotations for the given class\n",
    "    X_train_inst = X_train[train_inst]\n",
    "    \n",
    "    # Let's arrange the data for a sklearn Random Forest model \n",
    "    # Instead of having time-varying features, we'll summarize each track by its mean feature vector over time\n",
    "    X_train_inst_sklearn = np.mean(X_train_inst, axis=1)\n",
    "    \n",
    "    # Again, we slice the labels down \n",
    "    Y_true_train_inst = Y_true_train[train_inst, inst_num] >= 0.5\n",
    "\n",
    "    \n",
    "    \n",
    "    # Repeat the above slicing and dicing but for the test set\n",
    "    X_test_inst = X_test[test_inst]\n",
    "    X_test_inst_sklearn = np.mean(X_test_inst, axis=1)\n",
    "    Y_true_test_inst = Y_true_test[test_inst, inst_num] >= 0.5\n",
    "    \n",
    "    clf.fit(X_train_inst_sklearn, Y_true_train_inst)\n",
    "\n",
    "    # Finally, we'll evaluate the model on both train and test\n",
    "    \n",
    "    Y_pred_train = clf.predict(X_train_inst_sklearn)\n",
    "    Y_pred_test = clf.predict(X_test_inst_sklearn)\n",
    "    \n",
    "    print('-' * 52)\n",
    "    print(instrument)\n",
    "    print('\\tTRAIN')\n",
    "    print(classification_report(Y_true_train_inst, Y_pred_train))\n",
    "    print('\\tTEST')\n",
    "    print(classification_report(Y_true_test_inst, Y_pred_test))\n",
    "    \n",
    "    # Store the classifier in our dictionary\n",
    "    models[instrument] = clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's now use the model end-to-end on new audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/durand/miniconda2/envs/py36/lib/python3.6/site-packages/openmic/vggish/__model__/vggish_model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.61s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first go from audio to VGGish\n",
    "outpath = os.path.split(os.getcwd())[0] + '/tests/data/'\n",
    "file_in = [os.path.split(os.getcwd())[0] + '/tests/data/audio/000046_3840.ogg']\n",
    "featurefy.\n",
    "featurefy.main(file_in, outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = openmic.vggish.soundfile_to_examples()\n",
    "time_points, features = openmic.vggish.transform(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second go from VGGish to numpy format\n",
    "file_out = os.path.join(outpath,\n",
    "                        os.path.extsep.join([filebase(str(file_in)), 'npz']))\n",
    "vggish_new = np.load(file_out)\n",
    "time_len, _ = np.shape(vggish_new['features_z'])\n",
    "input_num = int(time_len / 10)\n",
    "X_new = np.empty([input_num, 10, 128], dtype=int)\n",
    "for ii in range(input_num):\n",
    "    X_new[ii, :, :] = vggish_new['features_z'][ii * 10:(ii+1) * 10, :]\n",
    "X_new_sklearn = np.concatenate((np.std(X_new, axis=1), np.std(X_new, axis=1)), axis=1)\n",
    "X_new_sklearn = np.nan_to_num(X_new_sklearn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_new_sklearn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-f0307f4de271>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#filename = os.getcwd() + '/baseline-models/clf_joblib_' + instrument + '.sav'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Probability of'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstrument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'is:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new_sklearn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_new_sklearn' is not defined"
     ]
    }
   ],
   "source": [
    "# finally, apply the classifier\n",
    "for instrument in models:\n",
    "    clf = models[instrument]\n",
    "    #filename = os.getcwd() + '/baseline-models/clf_joblib_' + instrument + '.sav'\n",
    "    \n",
    "    print('Probability of', instrument, 'is:', np.max(clf.predict_proba(X_new_sklearn)[:,1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
